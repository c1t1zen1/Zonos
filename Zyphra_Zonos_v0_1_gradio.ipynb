{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_iMpEme-9HS"
      },
      "source": [
        "# Zonos TTS Model - For Google Colab - Gradio with Emotion Settings\n",
        "## * MUST USE L4 or A100 GPU\n",
        "\n",
        "## Zonos by Zyphra is a cutting edge Text-To-Speech model with fast crisp clean voice cloning abilities. Apache 2.0 License\n",
        "\n",
        "This notebook clones the [Zonos repository](https://github.com/Zyphra/Zonos), installs the required system and Python dependencies, wait till cell has completed then click *restart session* before moving onto Gradio section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8YuTFHl-9HX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Initialize Zonos\n",
        "# Update package lists and install eSpeak (required for phonemization)\n",
        "!apt update && apt install -y espeak-ng\n",
        "\n",
        "# Clone the Zonos repository from GitHub\n",
        "!git clone https://github.com/Zyphra/Zonos.git\n",
        "%cd Zonos\n",
        "\n",
        "# Install Python dependencies using uv as recommended in the README cite50†\n",
        "!pip install -U uv\n",
        "!pip install -e .\n",
        "!pip install --no-build-isolation -e .[compile]\n",
        "\n",
        "!pip install numpy==1.24.4\n",
        "!pip install scipy==1.13.3\n",
        "!pip install scikit-learn==1.6.1\n",
        "!pip install triton\n",
        "\n",
        "# Must restart session !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbB0VDZc-9Hb"
      },
      "source": [
        "## Gradio section\n",
        "\n",
        "Gradio application, click Public Link URL in response to open gradio in a new browser tab, Then select the model, write the text prompt you want spoken, upload a sample voice and adjust settings to your liking.\n",
        "\n",
        "First run will take longer to load models and analyze voice uploaded before processing, further generations are much faster."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Launch Gradio with settings\n",
        "import torch\n",
        "import torchaudio\n",
        "import gradio as gr\n",
        "from zonos.model import Zonos\n",
        "from zonos.conditioning import make_cond_dict\n",
        "\n",
        "# Load the model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-hybrid\", device=device)\n",
        "\n",
        "def generate_speech(\n",
        "    model_choice,\n",
        "    text,\n",
        "    language,\n",
        "    speaker_audio,\n",
        "    prefix_audio,\n",
        "    happiness,\n",
        "    sadness,\n",
        "    disgust,\n",
        "    fear,\n",
        "    surprise,\n",
        "    anger,\n",
        "    other,\n",
        "    neutral,\n",
        "    vq_score,\n",
        "    fmax,\n",
        "    pitch_std,\n",
        "    speaking_rate,\n",
        "    dnsmos_ovrl,\n",
        "    denoise_speaker,\n",
        "    cfg_scale,\n",
        "    seed,\n",
        "    randomize_seed\n",
        "):\n",
        "    # Load and process the speaker audio\n",
        "    wav, sampling_rate = torchaudio.load(speaker_audio)\n",
        "    speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
        "\n",
        "    # Create emotion vector as a tensor\n",
        "    emotion_values = torch.tensor([\n",
        "        happiness, sadness, disgust, fear,\n",
        "        surprise, anger, other, neutral\n",
        "    ], device=device)\n",
        "    # Normalize the emotion values\n",
        "    emotion_values = emotion_values / emotion_values.sum()\n",
        "\n",
        "    # Create conditioning dictionary with all parameters\n",
        "    cond_dict = make_cond_dict(\n",
        "        text=text,\n",
        "        speaker=speaker,\n",
        "        language=language,\n",
        "        emotion=emotion_values,\n",
        "        vqscore_8=vq_score,\n",
        "        fmax=fmax,\n",
        "        pitch_std=pitch_std,\n",
        "        speaking_rate=speaking_rate,\n",
        "        dnsmos_ovrl=dnsmos_ovrl,\n",
        "        speaker_noised=denoise_speaker\n",
        "    )\n",
        "\n",
        "    # Handle seed\n",
        "    if randomize_seed or seed == -1:\n",
        "        seed = torch.randint(0, 1000000, (1,)).item()\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Generate speech\n",
        "    conditioning = model.prepare_conditioning(cond_dict)\n",
        "    codes = model.generate(\n",
        "        conditioning,\n",
        "        cfg_scale=cfg_scale\n",
        "    )\n",
        "    wavs = model.autoencoder.decode(codes).cpu()\n",
        "\n",
        "    # Save and return\n",
        "    output_path = \"output.wav\"\n",
        "    torchaudio.save(output_path, wavs[0], model.autoencoder.sampling_rate)\n",
        "    return output_path, seed\n",
        "\n",
        "# Available languages list\n",
        "LANGUAGES = ['af', 'am', 'an', 'ar', 'as', 'az', 'ba', 'bg', 'bn', 'bpy', 'bs', 'ca', 'cmn',\n",
        "            'cs', 'cy', 'da', 'de', 'el', 'en-029', 'en-gb', 'en-gb-scotland', 'en-gb-x-gbclan',\n",
        "            'en-gb-x-gbcwmd', 'en-gb-x-rp', 'en-us', 'eo', 'es', 'es-419', 'et', 'eu', 'fa',\n",
        "            'fa-latn', 'fi', 'fr-be', 'fr-ch', 'fr-fr', 'ga', 'gd', 'gn', 'grc', 'gu', 'hak',\n",
        "            'hi', 'hr', 'ht', 'hu', 'hy', 'hyw', 'ia', 'id', 'is', 'it', 'ja', 'jbo', 'ka',\n",
        "            'kk', 'kl', 'kn', 'ko', 'kok', 'ku', 'ky', 'la', 'lfn', 'lt', 'lv', 'mi', 'mk',\n",
        "            'ml', 'mr', 'ms', 'mt', 'my', 'nb', 'nci', 'ne', 'nl', 'om', 'or', 'pa', 'pap',\n",
        "            'pl', 'pt', 'pt-br', 'py', 'quc', 'ro', 'ru', 'ru-lv', 'sd', 'shn', 'si', 'sk',\n",
        "            'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'tn', 'tr', 'tt', 'ur', 'uz', 'vi',\n",
        "            'vi-vn-x-central', 'vi-vn-x-south', 'yue']\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"Zonos Text-to-Speech\") as demo:\n",
        "    gr.Markdown(\"# Zonos Text-to-Speech Generator\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            model_choice = gr.Dropdown(\n",
        "                choices=[\"Zyphra/Zonos-v0.1-transformer\", \"Zyphra/Zonos-v0.1-hybrid\"],\n",
        "                value=\"Zyphra/Zonos-v0.1-hybrid\",\n",
        "                label=\"Model Type\"\n",
        "            )\n",
        "            text = gr.Textbox(\n",
        "                label=\"Text to Speak\",\n",
        "                placeholder=\"Enter text to convert to speech...\",\n",
        "                value=\"Hello, this is a test of the Zonos text to speech system.\"\n",
        "            )\n",
        "            language = gr.Dropdown(\n",
        "                choices=LANGUAGES,\n",
        "                value=\"en-us\",\n",
        "                label=\"Language\"\n",
        "            )\n",
        "            speaker_audio = gr.Audio(\n",
        "                type=\"filepath\",\n",
        "                label=\"Speaker Voice Sample\"\n",
        "            )\n",
        "            prefix_audio = gr.Audio(\n",
        "                type=\"filepath\",\n",
        "                label=\"Prefix Audio (continue from this audio optional)\",\n",
        "                visible=True\n",
        "            )\n",
        "\n",
        "        with gr.Column():\n",
        "            with gr.Tab(\"Emotions\"):\n",
        "                happiness = gr.Slider(0, 1, value=0.2, label=\"Happiness\")\n",
        "                sadness = gr.Slider(0, 1, value=0.05, label=\"Sadness\")\n",
        "                disgust = gr.Slider(0, 1, value=0.05, label=\"Disgust\")\n",
        "                fear = gr.Slider(0, 1, value=0.05, label=\"Fear\")\n",
        "                surprise = gr.Slider(0, 1, value=0.05, label=\"Surprise\")\n",
        "                anger = gr.Slider(0, 1, value=0.05, label=\"Anger\")\n",
        "                other = gr.Slider(0, 1, value=0.1, label=\"Other\")\n",
        "                neutral = gr.Slider(0, 1, value=0.2, label=\"Neutral\")\n",
        "\n",
        "            with gr.Tab(\"Voice Parameters\"):\n",
        "                vq_score = gr.Slider(0, 1, value=0.78, label=\"VQ Score\")\n",
        "                fmax = gr.Slider(1000, 48000, value=48000, label=\"Fmax (Hz)\")\n",
        "                pitch_std = gr.Slider(0, 100, value=45, label=\"Pitch Std\")\n",
        "                speaking_rate = gr.Slider(0, 30, value=15, label=\"Speaking Rate\")\n",
        "                dnsmos_ovrl = gr.Slider(1, 5, value=4, label=\"DNSMOS Overall\")\n",
        "                denoise_speaker = gr.Checkbox(label=\"Denoise Speaker?\", value=False)\n",
        "\n",
        "            with gr.Tab(\"Generation Settings\"):\n",
        "                cfg_scale = gr.Slider(0, 10, value=2, label=\"CFG Scale\")\n",
        "                seed = gr.Number(value=-1, label=\"Seed (-1 for random)\")\n",
        "                randomize_seed = gr.Checkbox(label=\"Randomize Seed\", value=True)\n",
        "                output_seed = gr.Number(label=\"Last Used Seed\", interactive=False)\n",
        "\n",
        "            with gr.Column():\n",
        "                generate_btn = gr.Button(\"Generate Speech\")\n",
        "                output_audio = gr.Audio(label=\"Generated Speech\")\n",
        "\n",
        "    # Connect the generate button\n",
        "    generate_btn.click(\n",
        "        fn=generate_speech,\n",
        "        inputs=[\n",
        "            model_choice, text, language, speaker_audio, prefix_audio,\n",
        "            happiness, sadness, disgust, fear, surprise, anger, other, neutral,\n",
        "            vq_score, fmax, pitch_std, speaking_rate, dnsmos_ovrl, denoise_speaker,\n",
        "            cfg_scale, seed, randomize_seed\n",
        "        ],\n",
        "        outputs=[output_audio, output_seed]\n",
        "    )\n",
        "\n",
        "# Launch with public URL and full configuration\n",
        "demo.launch(share=True, debug=True, quiet=True)"
      ],
      "metadata": {
        "id": "Su4WQyq1B8YR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
